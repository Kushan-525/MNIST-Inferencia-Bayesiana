{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/ocar5/OneDrive/Documents/Codes/Python/MNIST/train.csv')\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros del modelo\n",
    "neu_entrada = 784  # Número de neuronas en la capa de entrada (corresponde a las características de los datos).\n",
    "neu_oculta = 25   # Número de neuronas en la capa oculta de la red neuronal. Este es un hiperparámetro a ajustar.\n",
    "neu_salida = 10   # Número de neuronas en la capa de salida (corresponde al número de clases).\n",
    "\n",
    "# Parámetros genéticos\n",
    "poblacion = 100     # Tamaño de la población de soluciones candidatas (redes neuronales) en cada generación.\n",
    "generaciones = 1000  # Número total de generaciones que el algoritmo genético ejecutará.\n",
    "prob_mutacion = 0.1  # Probabilidad de que un gen (peso) individual sufra una mutación.\n",
    "\n",
    "# Cálculo del tamaño total del vector\n",
    "def calculo_tam_vector():\n",
    "    # Calcula la longitud del vector que representa una red neuronal completa (pesos y sesgos).\n",
    "    return neu_oculta * neu_entrada + neu_oculta + neu_salida * neu_oculta + neu_salida\n",
    "\n",
    "tam_vector = calculo_tam_vector()  # Almacena el tamaño del vector calculado.\n",
    "\n",
    "# Codificar pesos y sesgos\n",
    "def encode_weights(W1, b1, W2, b2):\n",
    "    # Toma las matrices de pesos (W1, W2) y los vectores de sesgos (b1, b2) de la red neuronal\n",
    "    # y los aplana para concatenarlos en un único vector unidimensional que representa al individuo.\n",
    "    return np.concatenate([W1.flatten(), b1.flatten(), W2.flatten(), b2.flatten()])\n",
    "\n",
    "# Decodificar pesos y sesgos\n",
    "def deco_pesos(vector):\n",
    "    # Toma un vector unidimensional y lo reshapea para obtener las matrices de pesos y los vectores de sesgos\n",
    "    # de la red neuronal, utilizando las dimensiones predefinidas.\n",
    "    i = 0\n",
    "    W1 = vector[i:i + neu_oculta * neu_entrada].reshape((neu_oculta, neu_entrada))\n",
    "    i += neu_oculta * neu_entrada\n",
    "    b1 = vector[i:i + neu_oculta].reshape((neu_oculta, 1))\n",
    "    i += neu_oculta\n",
    "    W2 = vector[i:i + neu_salida * neu_oculta].reshape((neu_salida, neu_oculta))\n",
    "    i += neu_salida * neu_oculta\n",
    "    b2 = vector[i:i + neu_salida].reshape((neu_salida, 1))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Inicializar población\n",
    "def ini_poblacion():\n",
    "    # Crea una población inicial de individuos (vectores que representan redes neuronales)\n",
    "    # con valores aleatorios distribuidos uniformemente entre -1 y 1.\n",
    "    return [np.random.uniform(-1, 1, tam_vector) for _ in range(poblacion)]\n",
    "\n",
    "# Funciones de activación\n",
    "def ReLU(Z):\n",
    "    # Implementación de la función de activación ReLU (Rectified Linear Unit), que devuelve max(0, Z).\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    # Implementación de la función de activación Softmax, utilizada en la capa de salida para obtener\n",
    "    # probabilidades normalizadas para cada clase. Se incluye una resta del máximo para estabilidad numérica.\n",
    "    expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    return expZ / np.sum(expZ, axis=0, keepdims=True)\n",
    "\n",
    "# Propagación hacia adelante\n",
    "def forward_prop(X, W1, b1, W2, b2):\n",
    "    # Realiza la propagación hacia adelante a través de la red neuronal, calculando las salidas de cada capa.\n",
    "    Z1 = W1 @ X + b1  # Cálculo de la entrada a la capa oculta.\n",
    "    A1 = ReLU(Z1)     # Aplicación de la función de activación ReLU en la capa oculta.\n",
    "    Z2 = W2 @ A1 + b2  # Cálculo de la entrada a la capa de salida.\n",
    "    A2 = softmax(Z2)    # Aplicación de la función de activación Softmax en la capa de salida.\n",
    "    return A2\n",
    "\n",
    "# Evaluación de aptitud\n",
    "def eva_fitness(individual, X, Y):\n",
    "    # Evalúa la aptitud de un individuo calculando su exactitud en el conjunto de datos (X, Y).\n",
    "    W1, b1, W2, b2 = deco_pesos(individual)  # Decodifica el vector para obtener los pesos y sesgos.\n",
    "    A2 = forward_prop(X, W1, b1, W2, b2)     # Realiza la propagación hacia adelante para obtener las predicciones.\n",
    "    predictions = np.argmax(A2, axis=0)      # Obtiene la clase predicha con la mayor probabilidad.\n",
    "    return np.mean(predictions == Y)        # Calcula la exactitud comparando las predicciones con las etiquetas verdaderas.\n",
    "\n",
    "# Cruce de un punto\n",
    "def cruce(padre1, padre2):\n",
    "    # Implementa el operador de cruce de un punto. Se elige un punto aleatorio a lo largo del vector\n",
    "    # y se intercambian las secciones de los dos padres para crear dos nuevos hijos.\n",
    "    point = np.random.randint(1, tam_vector - 1)  # Elige un punto de cruce aleatorio.\n",
    "    hijo1 = np.concatenate([padre1[:point], padre2[point:]])  # Crea el primer hijo combinando la primera parte del padre1 y la segunda del padre2.\n",
    "    hijo2 = np.concatenate([padre2[:point], padre1[point:]])  # Crea el segundo hijo combinando la primera parte del padre2 y la segunda del padre1.\n",
    "    return hijo1, hijo2\n",
    "\n",
    "# Mutación suave\n",
    "def mutar(individual):\n",
    "    # Implementa un operador de mutación suave. Para cada gen (peso) en el individuo,\n",
    "    # existe una probabilidad de `prob_mutacion` de añadirle un pequeño valor aleatorio tomado de una distribución normal.\n",
    "    for i in range(tam_vector):\n",
    "        if np.random.rand() < prob_mutacion:\n",
    "            individual[i] += np.random.normal(0, 0.1)  # Añade una pequeña mutación aleatoria.\n",
    "    return individual\n",
    "\n",
    "# Algoritmo genético principal\n",
    "def algoritmo_genetico(X, Y):\n",
    "    # Implementa el algoritmo genético principal.\n",
    "    pobla = ini_poblacion()  # Inicializa la población.\n",
    "    elites = 5               # Número de los mejores individuos que se conservan directamente en la siguiente generación (elitismo).\n",
    "    lista_hist = []          # Lista para almacenar la exactitud de cada individuo en cada generación.\n",
    "\n",
    "    for generacion in range(generaciones):\n",
    "        # Evalúa la aptitud de cada individuo en la población actual.\n",
    "        puntajes = [eva_fitness(ind, X, Y) for ind in pobla]\n",
    "        lista_hist.append(puntajes)  # Guarda los puntajes de la generación actual.\n",
    "        # Ordena la población basándose en su aptitud (de mayor a menor).\n",
    "        pocision = [x for _, x in sorted(zip(puntajes, pobla), key=lambda pair: pair[0], reverse=True)]\n",
    "\n",
    "        # Imprime la mejor exactitud alcanzada en la generación actual.\n",
    "        print(f\"Generación {generacion} - Mejor Exactitud: {max(puntajes):.4f}\")\n",
    "\n",
    "        elite = pocision[:elites]  # Selecciona a los `elites` mejores individuos.\n",
    "        hijos = []                 # Lista para almacenar los nuevos individuos (hijos).\n",
    "\n",
    "        # Genera nuevos individuos hasta alcanzar el tamaño de la población deseado.\n",
    "        while len(elite) + len(hijos) < poblacion:\n",
    "            # Selecciona dos padres aleatoriamente del top 20 de la población ordenada.\n",
    "            indice_padres = np.random.choice(20, 2, replace=False)\n",
    "            padre1 = pocision[indice_padres[0]]\n",
    "            padre2 = pocision[indice_padres[1]]\n",
    "            # Aplica el operador de cruce para generar dos hijos.\n",
    "            hijo1, hijo2 = cruce(padre1, padre2)\n",
    "            # Aplica la mutación a los hijos y los añade a la lista de hijos.\n",
    "            hijos.append(mutar(hijo1))\n",
    "            if len(elite) + len(hijos) < poblacion:\n",
    "                hijos.append(mutar(hijo2))\n",
    "\n",
    "        # Crea la nueva población combinando los individuos de élite con los nuevos hijos.\n",
    "        pobla = elite + hijos\n",
    "\n",
    "    # Encuentra al mejor individuo de la última generación.\n",
    "    mejor_solo = max(pobla, key=lambda ind: eva_fitness(ind, X, Y))\n",
    "    return mejor_solo, lista_hist\n",
    "\n",
    "# Ejecutar algoritmo genético y evaluar en validación\n",
    "# digits = load_digits()\n",
    "# X = digits.data.T / 255.0\n",
    "# Y = digits.target\n",
    "# Y_one_hot = np.eye(10)[Y]\n",
    "# X_train, X_dev, Y_train, Y_dev_one_hot, Y_dev = train_test_split(X.T, Y_one_hot, Y, test_size=0.2, random_state=42)\n",
    "# X_train = X_train.T\n",
    "# X_dev = X_dev.T\n",
    "# Y_train = Y_train.flatten()\n",
    "# Y_dev = Y_dev.flatten()\n",
    "\n",
    "mejores_pesos, lista_hist = algoritmo_genetico(X_train, Y_train)\n",
    "\n",
    "# Decodificar mejores pesos\n",
    "W1, b1, W2, b2 = deco_pesos(mejores_pesos)\n",
    "\n",
    "# Evaluación en conjunto de validación\n",
    "A2 = forward_prop(X_dev, W1, b1, W2, b2)\n",
    "predictions = np.argmax(A2, axis=0)\n",
    "exact_eva = np.mean(predictions == Y_dev)\n",
    "print(f\"Exactitud en conjunto de validación: {exact_eva:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de precisión por generación\n",
    "prom_exactitud = [np.mean(g) for g in lista_hist]\n",
    "mejor_exactitud = [np.max(g) for g in lista_hist]\n",
    "\n",
    "plt.plot(prom_exactitud, label='Exactitud promedio')\n",
    "plt.plot(mejor_exactitud, label='Mejor Exactitud')\n",
    "plt.xlabel(\"Generación\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.title(\"Desempeño del algoritmo genético por generación\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
